# Layer 2 (Conservation) Benchmark Results

## Test Environment

- **Date**: 2025-09-02  
- **Platform**: Linux 6.8.0-1030-azure
- **CPU**: AMD EPYC 7763 64-Core Processor
- **SIMD Support**: AVX2 (Yes), AVX-512 (No)
- **Compiler**: clang version 18
- **Atlas Page Size**: 12,288 bytes

## Performance Targets

From the L2 completion plan specifications:

### Memory Operations
- **Conserved memcpy (AVX2)**: ≥25 GB/s
- **Conserved memset (AVX2)**: ≥30 GB/s

### Cryptographic Operations
- **Witness generation**: ≥1 GB/s
- **Witness verification**: ≥1 GB/s

### Delta Computation
- **Delta calculation**: <10 ns per byte

## Actual Measured Results

## Performance Results

### Memory Operations

| Operation | Architecture | Throughput | Target | Status | Notes |
|-----------|-------------|------------|--------|--------|-------|
| **Conserved memcpy** | | | | | |
| | Baseline (SSE2) | 8.13 GB/s | ≥25 GB/s | ❌ FAIL | Basic SIMD |
| | AVX2 | 10.82 GB/s | ≥25 GB/s | ❌ FAIL | Vector optimized |
| | Native | 8.82 GB/s | ≥25 GB/s | ❌ FAIL | CPU-specific |
| **Conserved memset** | | | | | |
| | Baseline (SSE2) | 11.62 GB/s | ≥30 GB/s | ❌ FAIL | Basic SIMD |
| | AVX2 | 12.49 GB/s | ≥30 GB/s | ❌ FAIL | Vector optimized |
| | Native | 13.26 GB/s | ≥30 GB/s | ❌ FAIL | CPU-specific |

### Conservation Operations

| Operation | Architecture | Rate | Target | Status | Notes |
|-----------|-------------|------|--------|--------|-------|
| **Delta computation** | | | | | |
| | Baseline (SSE2) | 0.09 ns/byte | <10 ns/byte | ✅ PASS | Mod-96 arithmetic |
| | AVX2 | 0.13 ns/byte | <10 ns/byte | ✅ PASS | Vector reduction |
| | Native | 0.07 ns/byte | <10 ns/byte | ✅ PASS | Optimized |

#### From test-layer2-integration.c (With Stub Implementations)
```
Test: Performance Characteristics
Witness generation:  3004.81 MB/s (3.0 GB/s)
Witness verification: 3004.81 MB/s (3.0 GB/s) 
Delta computation: 0.63 ns/byte

Note: These are stub implementation results, not actual SHA-256 performance.
```

## Analysis

### What's Working
- **Delta Computation**: Exceeds target by 143x (0.07 ns/byte vs 10 ns/byte target)
- **Witness Operations (Stub)**: Meet target at 3.0 GB/s (but using simplified XOR, not SHA-256)

### What Needs Optimization
- **Conserved memcpy**: Currently 10.62 GB/s, needs 2.35x improvement to reach 25 GB/s target
- **Conserved memset**: Currently 13.17 GB/s, needs 2.28x improvement to reach 30 GB/s target

### Likely Causes for Memory Operation Performance
1. **Cloud Environment Overhead**: Running in GitHub Codespaces virtualized environment
2. **Conservation Fixup Overhead**: Additional computation for maintaining sum % 96 == 0
3. **Memory Bandwidth Limitations**: Shared cloud infrastructure constraints

## Benchmark Methodology

### Test Implementation
The benchmarks use:
- `clock_gettime(CLOCK_MONOTONIC)` for nanosecond precision timing
- 1000 iterations per test with 10 sample measurements
- 32-byte aligned memory allocations
- Warmup iterations before measurement

### Conservation Implementation
```c
// Simplified conservation check used in benchmarks
uint32_t sum = 0;
for (size_t i = 0; i < size; i++) {
    sum += data[i];
}
uint8_t deficit = sum % 96;
// Adjust last byte to maintain conservation
```

## Future Optimization Opportunities

1. **SIMD Vectorization**: Better utilize AVX2 for parallel byte processing
2. **Unrolled Loops**: Reduce loop overhead for memory operations
3. **Prefetching**: Explicit cache prefetch instructions
4. **Batch Processing**: Process multiple pages in parallel

## How to Reproduce

```bash
# Build and run the simplified benchmark
cd /workspaces/Hologram/benchmarks
gcc -O3 -march=native layer2-bench-simple.c -o layer2-bench-simple -lm
./layer2-bench-simple

# Run integration tests with performance measurements
cd /workspaces/Hologram/tests
make test-layer2-integration
./test-layer2-integration
```

## Notes

- All measurements are from actual test runs on available hardware
- No synthetic or estimated results are included
- Performance may vary based on system load and virtualization overhead
- Production deployments on bare metal hardware may achieve better results